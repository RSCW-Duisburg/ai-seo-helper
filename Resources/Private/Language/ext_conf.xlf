<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<xliff version="1.0">
	<file source-language="en" datatype="plaintext" original="EXT:ai_seo_helper/Resources/Private/Language/locallang.xlf" date="2022-10-12T13:12:24Z" product-name="ai_seo_helper">
		<header/>
		<body>
            <trans-unit id="openAiApiKey" resname="openAiApiKey">
                <source>OpenAI Secret Key: Enter your generated API key or generate a new one under https://platform.openai.com/account/api-keys</source>
            </trans-unit>
            <trans-unit id="openAiPromptPrefixMetaDescription" resname="openAiPromptPrefixMetaDescription">
                <source>Prompt-Prefix for meta description generation: Enter your instruction for generating meta description</source>
            </trans-unit>
            <trans-unit id="showRawMetaDescriptionSuggestions" resname="showRawMetaDescriptionSuggestions">
                <source>Show raw response content of meta description suggestions: By default, the extension prepares the meta description suggestions in such a way that they can be selected via radio button. If you change the prompt prefix and no bullet point list is returned as a result, display problems can occur here. With this option you can output the raw content and select your favorite meta description via copy/paste.</source>
            </trans-unit>
            <trans-unit id="openAiPromptPrefixKeywords" resname="openAiPromptPrefixKeywords">
                <source>Prompt-Prefix for keywords generation: Enter your instruction for generating keywords</source>
            </trans-unit>
            <trans-unit id="replaceTextKeywords" resname="replaceTextKeywords">
                <source>Replace first part of generated keywords: The content generated by OpenAI is usually supplemented with a short introduction. Here you can define the part of the generated content that should be removed</source>
            </trans-unit>
            <trans-unit id="openAiPromptPrefixPageTitle" resname="openAiPromptPrefixPageTitle">
                <source>Prompt-Prefix for page title suggestions generation: Enter your instruction for generating page title suggestions (IMPORTANT: response must be a bullet point list as the return is processed that way)</source>
            </trans-unit>
            <trans-unit id="showRawPageTitleSuggestions" resname="showRawPageTitleSuggestions">
                <source>Show raw response content of page title suggestions: By default, the extension prepares the page title suggestions in such a way that they can be selected via radio button. If you change the prompt prefix and no bullet point list is returned as a result, display problems can occur here. With this option you can output the raw content and select your favorite page title via copy/paste.</source>
            </trans-unit>
            <trans-unit id="openAiModel" resname="openAiModel">
                <source>OpenAI Model: The id of the model which will generate the completion. See https://platform.openai.com/docs/models/gpt-3-5 for an overview of available models.</source>
            </trans-unit>
            <trans-unit id="openAiTemperature" resname="openAiTemperature">
                <source>OpenAI Temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.</source>
            </trans-unit>
            <trans-unit id="openAiMaxTokens" resname="openAiMaxTokens">
                <source>OpenAI Max-Tokens: The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096).</source>
            </trans-unit>
            <trans-unit id="openAiTopP" resname="openAiTopP">
                <source>OpenAI Top-P: An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.</source>
            </trans-unit>
            <trans-unit id="openAiFrequencyPenalty" resname="openAiFrequencyPenalty">
                <source>OpenAI Frequency Penalty: Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.</source>
            </trans-unit>
            <trans-unit id="openAiPresencePenalty" resname="openAiPresencePenalty">
                <source>OpenAI Presence Penalty: Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.</source>
            </trans-unit>
            <trans-unit id="useUrlForRequest" resname="useUrlForRequest">
                <source>Use always URL for requests: With this option you can use the corresponding URL of the page for all analyses. As a result, you have to use fewer tokens to carry out your corresponding analyses. IMPORTANT: The page must be publicly accessible (hidden pages fail and pages in a local environment lead to poor results)</source>
            </trans-unit>
            <trans-unit id="maxAllowedCharacters" resname="maxAllowedCharacters">
                <source>Maximum characters per request: Here you can additionally limit the maximum number of allowed characters. By default, OpenAI allows a maximum of 4096 tokens per request, which corresponds to around 16000 to 16350 characters (in English). Special characters are "more expensive" than normal characters, which means that a token can sometimes be less than 4 characters. For more information see https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them</source>
            </trans-unit>
		</body>
	</file>
</xliff>
